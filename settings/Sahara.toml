#----------------------------------------------------SAHARA CONTROL-----------------------------------------------------

SAHARA_TRANSFER_AMOUNT = [1e-05, 2e-05] # —Å—É–º–º–∞ SAH –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–∞ –Ω–∞ —Ä–∞–Ω–¥–æ–º–Ω—ã–π –∫–æ—à–µ–ª–µ–∫
SAHARA_LOGIN_VIA_REF_CODE = false # –ø–æ—Å—Ç–∞–≤—å—Ç–µ true, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ—Ñ–µ—Ä—Ä–∞–ª—å–Ω—ã–π –∫–æ–¥ –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ —Å–∞–π—Ç–µ
SAHARA_PROCESS_ONCHAIN = true # –ø–æ—Å—Ç–∞–≤—å—Ç–µ true, —á—Ç–æ–±—ã –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –æ–Ω—á–µ–π–Ω –∑–∞–¥–∞–Ω–∏—è
SAHARA_FAUCET_UNLIMITED = true # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—Ä–∞–Ω –ø—Ä–∏ –ª—é–±–æ–º –±–∞–ª–∞–Ω—Å–µ –Ω–∞ –∞–∫–∫–∞—É–Ω—Ç–µ, –Ω–µ –∑–∞–±—É–¥—å—Ç–µ –≤—Å—Ç–∞–≤–∏—Ç—å –∫–ª—é—á –≤ –≥–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
SAHARA_SELF_TRANSFERS = false # –ø–æ—Å—Ç–∞–≤—å—Ç–µ true, –¥–µ–ª–∞—Ç—å —Ç—Ä–∞–Ω—Å—Ñ–µ—Ä—ã –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–¥—Ä–µ—Å. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–∞ —Ä–∞–Ω–¥–æ–º–Ω—ã–π

SAHARA_TRANSFER_SAH_AMOUNT = [0.005, 0.006] # —Å—É–º–º–∞ –¥–ª—è —Ç—Ä–∞–Ω—Ñ–µ—Ä–∞ SAH –≤ —Å–µ—Ç–∏ Sahara –Ω–∞ –∫–æ—à–µ–ª–µ–∫ –∏–∑ EVM Deposit Address
SAHARA_TRANSFER_ETH_AMOUNT = ["100", "100"] # —Å—É–º–º–∞ –¥–ª—è —Ç—Ä–∞–Ω—Ñ–µ—Ä–∞ ETH –≤ —Å–µ—Ç–∏ Ethereum –Ω–∞ –∫–æ—à–µ–ª–µ–∫ –∏–∑ EVM Deposit Address

#----------------------------------------------------SAHARA DATASET-----------------------------------------------------

SAHARA_DATASET_AI_TYPE = 2 # 1 - Nous AI, 2 - ChatGPT
SAHARA_DATASET_COUNTS = [20, 30] # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è –¥–µ–ø–ª–æ—è –Ω–∞ –∞–∫–∫–∞—É–Ω—Ç–µ
SAHARA_DATASET_MAX_TOKENS = [100, 120] # (–º–∏–Ω, –º–∞–∫—Å) –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç AI
SAHARA_DATASET_FILE_TYPE = 2 # 1 - CSV / 2 - JSON / 3 - TXT
SAHARA_DATASET_PROMTS = [
    "You are an intelligent assistant designed to generate high-quality, structured synthetic datasets in JSON format for machine learning, artificial intelligence, and NLP applications. Your job is to automatically produce text-based datasets that are clean, diverse, and ready to be uploaded to AI platforms, marketplaces, or used in custom AI pipelines. üîπ Supported dataset types include: Educational tasks (math, physics, chemistry, logic, theory), Question-answer pairs (trivia, exams, study guides, chatbots), Classification tasks (cars, animals, drinks, symptoms, dictionaries), Structured logs (dialogues, action tracking, journaling, note-taking), User command datasets (intents, emotions, tone, action labels). üîπ Output format: JSON array of objects, Each object must have clearly defined fields relevant to the topic, Format must be clean and valid JSON (no comments, no metadata), Default language: English (unless user specifies otherwise). üîπ What you must do: 1. Infer the dataset structure (fields) from the topic the user provides, 2. Generate 5 to 20 unique, varied, and plausible data entries, 3. Ensure the examples are synthetic but realistic and useful, 4. Output only valid JSON ‚Äî no explanations or extra formatting, 5. Avoid duplication and keep field values consistent and logically accurate. üîπ Example user prompt: ‚ÄúCreate a JSON dataset of trivia questions about chemistry.‚Äù üîπ Your response must be: A JSON array of question objects, Fields: question, answer, topic, difficulty, No extra explanation, just the raw dataset. üîí Important rules: Do not invent overly complicated or deep structures, Keep it clean, relevant, and easy to parse for training AI models, Focus on utility: make the dataset meaningful and adaptable, Think like an API that powers training workflows. Your goal is to be a flawless dataset generation engine that delivers highly structured, high-signal, text-based datasets on demand."
] # –ø—Ä–æ–º—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è AI –º–æ–¥–µ–ª–µ–π, –º–æ–∂–Ω–æ —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ.
